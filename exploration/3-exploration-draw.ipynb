{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# screen resolution\n",
    "monitor_width = 3440\n",
    "monitor_height = 1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame, scale):\n",
    "\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "\n",
    "    return cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def find_scale_factor(frame, monitor_width, monitor_height):\n",
    "    \"\"\"\n",
    "    Rescales the frame if it is larger than the monitor \n",
    "    \"\"\"\n",
    "\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "    if (frame_width > monitor_width) or (frame_height > monitor_height):\n",
    "        with_scale = monitor_width / frame_width\n",
    "        height_scale = monitor_height / frame_height\n",
    "        return min(with_scale, height_scale)\n",
    "\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frames = pd.read_csv('../data/tmp_tracking.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedal position while horizontal pedals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.960] global loadsave.cpp:241 findDecoder imread_('../data/tmp_frames/frame_     frame                          hip                         knee  \\\n",
      "892    893  [229.61586714 317.24868774]  [170.38742423 358.6038208 ]   \n",
      "405    406  [228.17612171 317.03281403]  [168.78598452 353.87317657]   \n",
      "844    845  [228.27789545 319.14611816]  [167.3450911  352.20867157]   \n",
      "\n",
      "                           ankle                  ankle_right  \\\n",
      "892  [183.11395884 431.86344147]  [222.36270189 431.12194061]   \n",
      "405  [186.63378954 430.67718506]  [221.4908123  431.07147217]   \n",
      "844  [183.46150875 430.84754944]  [217.89315462 430.06950378]   \n",
      "\n",
      "                        shoulder                        elbow  \\\n",
      "892  [170.76305151 272.1087265 ]  [148.67548943 318.97632599]   \n",
      "405  [172.47549176 260.67001343]  [143.31851721 306.77845001]   \n",
      "844  [163.563627   281.40497208]  [151.84125781 331.55124664]   \n",
      "\n",
      "                           wrist  angle_knee  angle_shoulder  angle_elbow  \\\n",
      "892  [103.3280468  334.58900452]  115.068964       77.745249   134.231446   \n",
      "405  [ 99.63478446 332.51857758]  108.729514       76.968934   152.815705   \n",
      "844  [103.22319388 335.41099548]  106.902615       72.906800   107.696540   \n",
      "\n",
      "     angle_torso  angle_pedal  min_height_ankle  parallel_pedals  \n",
      "892    37.488115     1.082323             False             True  \n",
      "405    45.338551     0.648077             False             True  \n",
      "844    30.250595     1.294482             False             True  .jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/tmp_frames/frame_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_frame\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# does not depend on the monitor resolution\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[43mfind_scale_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m img_rescaled \u001b[38;5;241m=\u001b[39m rescale_frame(img, scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapture_event\u001b[39m(event, x, y, flags, param):\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mfind_scale_factor\u001b[0;34m(frame, monitor_width, monitor_height)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_scale_factor\u001b[39m(frame, monitor_width, monitor_height):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Rescales the frame if it is larger than the monitor \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     frame_width \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m     frame_height \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (frame_width \u001b[38;5;241m>\u001b[39m monitor_width) \u001b[38;5;129;01mor\u001b[39;00m (frame_height \u001b[38;5;241m>\u001b[39m monitor_height):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "frames_parallel_pedals = df_frames[df_frames['parallel_pedals'] == True]\n",
    "\n",
    "# sample a frame from frames_parallel_pedals\n",
    "sample_frame = frames_parallel_pedals.sample(1)['frame'].values[0]\n",
    "\n",
    "img = cv2.imread(f'../data/tmp_frames/frame_{sample_frame}.jpg')\n",
    "\n",
    "# does not depend on the monitor resolution\n",
    "scale = find_scale_factor(img, monitor_width, monitor_height)\n",
    "img_rescaled = rescale_frame(img, scale=scale)\n",
    "\n",
    "def capture_event(event, x, y, flags, param):\n",
    "    captured = False\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "\n",
    "        # make a copy of the image\n",
    "        img_rescaled_tmp = img_rescaled.copy()\n",
    "\n",
    "        # plot a green vertical and horizontal line\n",
    "        cv2.line(img_rescaled_tmp, (x, 0), (x, img_rescaled.shape[0]), (0, 255, 0), 1)\n",
    "        cv2.line(img_rescaled_tmp, (0, y), (img_rescaled.shape[1], y), (0, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow(\"frame\", img_rescaled_tmp)\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f\"Captured coordinates ({x}, {y}), press any key to exit\")\n",
    "\n",
    "\n",
    "cv2.imshow('frame', img_rescaled)\n",
    "cv2.setMouseCallback('frame', capture_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736529310.308237  827699 gl_context.cc:369] GL version: 2.1 (2.1 INTEL-20.2.48), renderer: Intel(R) Iris(TM) Plus Graphics OpenGL Engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1736529310.652696  836105 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736529310.708012  836105 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from functions.video_processing import get_coordinates_from_video\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# screen resolution\n",
    "monitor_width = 3440\n",
    "monitor_height = 1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame, scale):\n",
    "\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "\n",
    "    return cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def find_scale_factor(frame, monitor_width, monitor_height):\n",
    "    \"\"\"\n",
    "    Rescales the frame to the size of monitor\n",
    "    \"\"\"\n",
    "\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "    if (frame_width > monitor_width) or (frame_height > monitor_height):\n",
    "        with_scale = monitor_width / frame_width\n",
    "        height_scale = monitor_height / frame_height\n",
    "        return min(with_scale, height_scale)\n",
    "    \n",
    "    if (frame_width < monitor_width) and (frame_height < monitor_height):\n",
    "        with_scale = monitor_width / frame_width\n",
    "        height_scale = monitor_height / frame_height\n",
    "        return min(with_scale, height_scale)\n",
    "\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frames = pd.read_csv('../data/tmp_tracking.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedal position for knee-over-pedal calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedal_coordinates_sampled = []\n",
    "tube_coordinates_sampled = []\n",
    "frames_parallel_pedals = df_frames[df_frames['parallel_pedals'] == True]\n",
    "\n",
    "# sample a frame from frames_parallel_pedals\n",
    "sample_frames = frames_parallel_pedals.sample(3)['frame'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 3 - Captured coordinates (362, 1046), press any key to continue\n",
      "iteration 2 of 3 - Captured coordinates (362, 1035), press any key to continue\n",
      "iteration 3 of 3 - Captured coordinates (347, 1037), press any key to continue\n",
      "Pedal coordinates obtained (original frame sizes): [158 461]\n"
     ]
    }
   ],
   "source": [
    "pedal_coordinates_sampled = get_coordinates_from_video(sample_frames, monitor_width, monitor_height, msg='', type_coordinates='point')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 3 - Captured coordinates (366, 1040), press any key to continue\n",
      "iteration 2 of 3 - Captured coordinates (362, 1039), press any key to continue\n",
      "iteration 3 of 3 - Captured coordinates (367, 1035), press any key to continue\n",
      "Pedal coordinates obtained (original frame sizes): [162 461]\n"
     ]
    }
   ],
   "source": [
    "for i, sample_frame in enumerate(sample_frames):\n",
    "    img = cv2.imread(f'../data/tmp_frames/frame_{sample_frame}.jpg')\n",
    "\n",
    "    # does not depend on the monitor resolution\n",
    "    scale = find_scale_factor(img, monitor_width, monitor_height)\n",
    "    img_rescaled = rescale_frame(img, scale=scale)\n",
    "\n",
    "\n",
    "    def capture_event(event, x, y, flags, param):\n",
    "        captured = False\n",
    "\n",
    "        # make a copy of the image\n",
    "        img_rescaled_tmp = img_rescaled.copy()\n",
    "\n",
    "        if event == cv2.EVENT_MOUSEMOVE:\n",
    "\n",
    "            # plot a green vertical and horizontal line\n",
    "            cv2.line(img_rescaled_tmp, (x, 0), (x, img_rescaled.shape[0]), (0, 255, 0), 1)\n",
    "            cv2.line(img_rescaled_tmp, (0, y), (img_rescaled.shape[1], y), (0, 255, 0), 1)\n",
    "\n",
    "            cv2.imshow(\"frame\", img_rescaled_tmp)\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            print(f\"iteration {i + 1} of 3 - Captured coordinates ({x}, {y}), press any key to continue\")\n",
    "            pedal_coordinates_sampled.append((x, y))\n",
    "            cv2.destroyWindow(\"frame\")\n",
    "\n",
    "\n",
    "    cv2.imshow('frame', img_rescaled)\n",
    "    cv2.setMouseCallback('frame', capture_event)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# pedal coordinates obtained in the resized monitor\n",
    "pedal_coordinates = ((1 / scale) * np.array(pedal_coordinates_sampled).mean(axis=0)).astype(int)\n",
    "\n",
    "print(f\"Pedal coordinates obtained (original frame sizes): {pedal_coordinates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tube length identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured tube coordinates (297, 808), press any key to continue\n",
      "Captured tube coordinates (488, 854), press any key to continue\n",
      "Tube coordinates obtained (rescaled image): [(297, 808), (488, 854)]\n",
      "press any key to continue ...\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(f'../data/tmp_frames/frame_{sample_frames[0]}.jpg')\n",
    "\n",
    "# does not depend on the monitor resolution\n",
    "img_rescaled = rescale_frame(img, scale=scale)\n",
    "\n",
    "\n",
    "def capture_event(event, x, y, flags, param):\n",
    "    captured = False\n",
    "\n",
    "    # make a copy of the image\n",
    "    img_rescaled_tmp = img_rescaled.copy()\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "\n",
    "        # plot a green vertical and horizontal line\n",
    "        cv2.line(img_rescaled_tmp, (x, 0), (x, img_rescaled.shape[0]), (0, 255, 0), 1)\n",
    "        cv2.line(img_rescaled_tmp, (0, y), (img_rescaled.shape[1], y), (0, 255, 0), 1)\n",
    "        cv2.imshow(\"frame\", img_rescaled_tmp)\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f\"Captured tube coordinates ({x}, {y}), press any key to continue\")\n",
    "        tube_coordinates_sampled.append((x, y))\n",
    "\n",
    "\n",
    "        if len(tube_coordinates_sampled) == 2:\n",
    "            cv2.line(img_rescaled_tmp, tube_coordinates_sampled[0], tube_coordinates_sampled[1], (0, 0, 255), 2)\n",
    "            cv2.imshow(\"frame\", img_rescaled_tmp)\n",
    "            cv2.waitKey(200)\n",
    "            cv2.destroyWindow(\"frame\")\n",
    "\n",
    "            print(f'Tube coordinates obtained (rescaled image): {tube_coordinates_sampled}')\n",
    "            print('press any key to continue ...')\n",
    "\n",
    "\n",
    "cv2.imshow('frame', img_rescaled)\n",
    "cv2.setMouseCallback('frame', capture_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "tube_coordinates_sampled = ((1 / scale) * np.array(tube_coordinates_sampled)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_pixel_size = np.linalg.norm(tube_coordinates_sampled[0] - tube_coordinates_sampled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.34813257969161"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_pixel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
